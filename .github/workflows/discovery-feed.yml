name: Discovery Feed Generator

on:
  schedule:
    # Run daily at 4 AM UTC
    - cron: '0 4 * * *'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to process (YYYY-MM-DD)'
        required: false
        default: ''

jobs:
  discovery-build:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        cd holler-discovery
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        # Install in development mode
        pip install -e .
    
    - name: Set date variable
      id: date
      run: |
        if [ -n "${{ github.event.inputs.date }}" ]; then
          echo "date=${{ github.event.inputs.date }}" >> $GITHUB_OUTPUT
        else
          echo "date=$(date -u +%F)" >> $GITHUB_OUTPUT
        fi
    
    - name: Run database migrations
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
      run: |
        cd holler-discovery
        python -c "
        import asyncio
        from src.db import migrate_db
        asyncio.run(migrate_db())
        print('Database migrations completed successfully')
        "
    
    - name: Ingest Certificate Transparency logs
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        CT_LOOKBACK_HOURS: 24
      run: |
        cd holler-discovery
        python -c "
        import asyncio
        from src.ingest.ct import ingest_ct
        result = asyncio.run(ingest_ct(24))
        print(f'CT ingestion completed: {result} URLs inserted')
        "
    
    - name: Ingest RSS feeds
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        RSS_FEEDS_PATH: config/feeds.txt
      run: |
        cd holler-discovery
        python -c "
        import asyncio
        from src.ingest.rss import ingest_rss
        result = asyncio.run(ingest_rss('config/feeds.txt'))
        print(f'RSS ingestion completed: {result} URLs inserted')
        "
    
    - name: Ingest Common Crawl Index
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        CC_URL_LIMIT: 10000
        CC_DATASETS_RECENT: 3
      run: |
        cd holler-discovery
        python -c "
        import asyncio
        from src.ingest.commoncrawl import ingest_cc
        result = asyncio.run(ingest_cc(10000))
        print(f'Common Crawl ingestion completed: {result} URLs inserted')
        "
    
    - name: Filter and deduplicate URLs
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        HOST_CAP: 500
        PARKING_THRESHOLD: 0.3
        NOVELTY_THRESHOLD: 0.5
      run: |
        cd holler-discovery
        python -c "
        from src.pipeline.filters import filter_raw_urls
        result = filter_raw_urls(500)
        print(f'Filtering completed: {result} URLs moved to discovered_kept')
        "
    
    - name: Generate discovery pages
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        LINKS_PER_PAGE: 200
        BASE_URL: https://holler.news
      run: |
        cd holler-discovery
        python -c "
        from src.pipeline.html_writer import HTMLWriter
        writer = HTMLWriter(output_dir='../client/build')
        generated_files = writer.generate_discovery_pages('${{ steps.date.outputs.date }}')
        print(f'Generated {len(generated_files)} files for ${{ steps.date.outputs.date }}')
        for file_path in generated_files:
            print(f'  {file_path}')
        "
    
    - name: Generate sitemaps
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        BASE_URL: https://holler.news
        SITEMAP_URLS_PER_FILE: 50000
      run: |
        cd holler-discovery
        python -c "
        from src.pipeline.sitemap_writer import SitemapWriter
        writer = SitemapWriter(output_dir='../client/build', base_url='https://holler.news')
        generated_files = writer.generate_sitemaps()
        print(f'Generated {len(generated_files)} sitemap files')
        for file_path in generated_files:
            print(f'  {file_path}')
        "
    
    - name: Check for changes
      id: changes
      run: |
        if git diff --quiet; then
          echo "changed=false" >> $GITHUB_OUTPUT
        else
          echo "changed=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push changes
      if: steps.changes.outputs.changed == 'true'
      run: |
        cd holler-discovery
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        # Commit generated files
        git add ../client/build/discover ../client/build/sitemaps ../client/build/sitemap-index.xml || echo "No new files to add"
        if git diff --cached --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Update discovery feed - $(date -u +'%Y-%m-%d %H:%M:%S')"
          git push origin main
          echo "Changes committed and pushed successfully"
        fi
    
    - name: No changes to commit
      if: steps.changes.outputs.changed == 'false'
      run: echo "No changes detected, skipping commit"
    
    - name: Run statistics
      env:
        DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
      run: |
        cd holler-discovery
        echo "=== Discovery Feed Statistics ==="
        python -c "
        from src.pipeline.manifest import get_daily_stats
        stats = get_daily_stats('${{ steps.date.outputs.date }}')
        print('=== Discovery Feed Statistics ===')
        print(f'Date: {stats.get(\"date\", \"N/A\")}')
        print(f'Raw Count: {stats.get(\"raw_count\", 0)}')
        print(f'Kept Count: {stats.get(\"kept_count\", 0)}')
        print(f'Filter Rate: {stats.get(\"filter_rate\", 0):.2%}')
        "
